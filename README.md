
# Fine-Tuning de LLMs com QLoRA para Tarefas Text-to-SQL

Este repositÃ³rio contÃ©m um pipeline completo para o fine-tuning de Modelos de Linguagem Grandes (LLMs) utilizando a tÃ©cnica de QLoRA, com foco na tarefa de conversÃ£o de texto para SQL (Text-to-SQL). O projeto utiliza o modelo `openlm-research/open_llama_3b_v2` e o dataset [Spider](https://yale-lily.github.io/spider).

AlÃ©m de treinar e avaliar o desempenho na tarefa especÃ­fica, o projeto tambÃ©m realiza umaÃ¡lise de regressÃ£o de capacidade, medindo o impacto do fine-tuning nas habilidades de conhecimento geral do modelo atravÃ©s do benchmark MMLU.

## âœ¨ Funcionalidades

* **AvaliaÃ§Ã£o de Baseline**: Mede a performance do modelo base (`openlm-research/open_llama_3b_v2`) tanto na tarefa Text-to-SQL (com a mÃ©trica de acurÃ¡cia de execuÃ§Ã£o) quanto no benchmark de conhecimento geral MMLU.
* **PrÃ©-processamento de Dados**: Formata e prepara o dataset Spider para o treinamento no formato de chat, adequado para modelos de instruÃ§Ã£o.
* **Treinamento com QLoRA**: Realiza o fine-tuning do LLM de forma eficiente em termos de memÃ³ria, utilizando a tÃ©cnica QLoRA e o `SFTTrainer` da biblioteca TRL.
* **AnÃ¡lise PÃ³s-Treinamento**: Avalia o modelo apÃ³s o fine-tuning para quantificar a melhoria na tarefa de Text-to-SQL.
* **AnÃ¡lise de RegressÃ£o**: Compara a performance do modelo treinado com o modelo base no benchmark MMLU para identificar possÃ­veis perdas de capacidade em domÃ­nios de conhecimento geral.

## âš™ï¸ Setup e InstalaÃ§Ã£o

Siga os passos abaixo para configurar o ambiente de execuÃ§Ã£o.

### 1. Clone o RepositÃ³rio
```bash
git clone [https://github.com/seu-usuario/LLMs-FT-QLoRA.git](https://github.com/seu-usuario/LLMs-FT-QLoRA.git)
cd LLMs-FT-QLoRA
````

### 2\. Baixe o Dataset Spider

**Ã‰ necessÃ¡rio baixar o dataset Spider, que contÃ©m os bancos de dados utilizados para o treinamento e avaliaÃ§Ã£o.**

Acesse o site oficial do [Spider](https://yale-lily.github.io/spider), baixe o arquivo `spider.zip` (que inclui os bancos de dados) e renomeie-o para `spider_data.zip`. Em seguida, **coloque o arquivo `spider_data.zip` na pasta raiz do projeto.** O script `main.py` irÃ¡ descompactÃ¡-lo automaticamente na primeira execuÃ§Ã£o.

### 3\. Instale as DependÃªncias

Este projeto utiliza as dependÃªncias listadas no arquivo `requirements.txt`. Para instalÃ¡-las, execute o comando:

```bash
pip install -r requirements.txt
```

O arquivo jÃ¡ inclui o link extra para o PyTorch, garantindo a compatibilidade com ambientes CUDA mais recentes, como o do Google Colab.

## ğŸš€ Como Executar

Com o ambiente configurado e o arquivo `spider_data.zip` na raiz do projeto, vocÃª pode executar todo o pipeline de treinamento e avaliaÃ§Ã£o com um Ãºnico comando:

```bash
python main.py
```

O script cuidarÃ¡ de todas as etapas: avaliaÃ§Ã£o do baseline, prÃ©-processamento, treinamento com diferentes hiperparÃ¢metros e a avaliaÃ§Ã£o final.

## â˜ï¸ Executando no Google Colab

Para facilitar a execuÃ§Ã£o utilizando os recursos de GPU do Google Colab, utilize o notebook **`run_google_colab.ipynb`**. Ele contÃ©m os passos necessÃ¡rios para configurar o ambiente e executar o projeto na nuvem.

## ğŸ”§ ConfiguraÃ§Ã£o

As principais configuraÃ§Ãµes do experimento podem ser ajustadas diretamente no inÃ­cio do arquivo `main.py`:

  * `BASE_MODEL_ID`: O identificador do modelo base no Hugging Face Hub.
  * `SAMPLE_SIZE_EVAL` e `SAMPLE_SIZE_TRAIN`: Permitem definir um nÃºmero menor de amostras para testes rÃ¡pidos. Defina-os como `None` para usar os datasets completos.
  * `TRAINING_CONFIGS`: Uma lista de dicionÃ¡rios onde vocÃª pode especificar diferentes configuraÃ§Ãµes de hiperparÃ¢metros (como `learning_rate` e `num_train_epochs`) para cada execuÃ§Ã£o do treinamento.

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ custom_metrics/
â”‚   â””â”€â”€ execution_accuracy.py   # MÃ©trica customizada para acurÃ¡cia de execuÃ§Ã£o SQL
â”œâ”€â”€ results/
â”‚   â””â”€â”€ ...                     # Pasta onde os adaptadores treinados sÃ£o salvos
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ evaluate.py             # MÃ³dulos de avaliaÃ§Ã£o (MMLU, Text-to-SQL)
â”‚   â”œâ”€â”€ pre_proc.py             # MÃ³dulo de prÃ©-processamento de dados
â”‚   â””â”€â”€ training.py             # Classe para o treinamento do modelo com LoRA
â”œâ”€â”€ main.py                     # Script principal para execuÃ§Ã£o do pipeline
â”œâ”€â”€ requirements.txt            # Lista de dependÃªncias do projeto
â”œâ”€â”€ run_google_colab.ipynb      # Notebook para execuÃ§Ã£o no Google Colab
â””â”€â”€ spider_data.zip             # (Requerido) Dataset Spider a ser baixado pelo usuÃ¡rio
```

```
```
